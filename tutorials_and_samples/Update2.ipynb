{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de03c3b6",
   "metadata": {},
   "source": [
    "**Name:** Alex Medina\n",
    "\n",
    "**File:** Comprehensive Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3dd0b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e86e5a60-271d-4694-8580-02aa5ba950bd\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"e86e5a60-271d-4694-8580-02aa5ba950bd\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e86e5a60-271d-4694-8580-02aa5ba950bd\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['picaso_refdata'] = r'C:\\Users\\Alex\\Desktop\\Picaso\\picaso\\reference' #THIS MUST GO BEFORE YOUR IMPORT STATEMENT\n",
    "os.environ['PYSYN_CDBS'] = r'C:\\Users\\Alex\\Desktop\\Picaso\\grp\\redcat\\trds' #this is for the stellar data discussed below.\n",
    "\n",
    "#General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Picaso\n",
    "from picaso import justdoit as jdi\n",
    "from picaso import justplotit as jpi\n",
    "\n",
    "# Virga\n",
    "from virga import justdoit as vj\n",
    "from virga import justplotit as cldplt\n",
    "\n",
    "# Other\n",
    "from bokeh.models import Legend\n",
    "from bokeh.plotting import show, figure\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bdaab5",
   "metadata": {},
   "source": [
    "**SECTION 1:** Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5f4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR FUTURE INTERPOLATING PICKLE VALUES\n",
    "def interpl(P_bar, T_K, **kwargs):\n",
    "    \"\"\"\n",
    "    TP override/modifier (FUTURE):\n",
    "    - TODAY: return inputs unchanged.\n",
    "    - LATER: drop in your interpolation-to-higher-res or apply a pickle modifier.\n",
    "    \"\"\"\n",
    "    return P_bar, T_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24a0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting clouds instead of harcoding cloud species\n",
    "# Select using virga condensation\n",
    "\n",
    "def autoselect_clouds(P_bar, T_K, mmw, p_cutoff=1e-2):\n",
    "    \"\"\"\n",
    "    Pick condensates present somewhere above ~10 mbar (P >= p_cutoff).\n",
    "    \"\"\"\n",
    "\n",
    "    cloud_species = [\"Al2O3\",\"Cr\",\"Fe\",\"H2O\",\"KCl\",\"Mg2SiO4\",\n",
    "                     \"MgSiO3\",\"MnS\",\"NH3\",\"Na2S\",\"ZnS\"]\n",
    "    \n",
    "    P = np.asarray(P_bar, float)\n",
    "    T = np.asarray(T_K,   float)\n",
    "\n",
    "    sel = []\n",
    "    for sp in cloud_species:\n",
    "        # Returns condensation T at each P\n",
    "        _, Tcond = vj.condensation_t(sp, 1.0, mmw, pressure=P)\n",
    "\n",
    "        # Builds a boolean mask of “valid” levels to check\n",
    "        # Only deeper than p_cut\n",
    "        # Where T and Tcond are both finite\n",
    "        mask = (P >= p_cutoff) & np.isfinite(T) & np.isfinite(Tcond)\n",
    "\n",
    "        # Test if there exists at least 1 level where atmosphere is\n",
    "        # Cold enough to condense\n",
    "        # I.e. if there are any T < Tcond\n",
    "        # The condensate can forn in the column\n",
    "        if mask.any() and np.any(T[mask] <= Tcond[mask]):\n",
    "            # Cloud species added to profile\n",
    "            sel.append(sp)\n",
    "    return sel\n",
    "\n",
    "# Cloud selection depends on MMW, but I feel that I am making loops here\n",
    "def compute_mmw(profile_dict, fallback=2.36):\n",
    "    \"\"\"\n",
    "    Computing mmw from Sonora profile if present; else use solar mmw.\n",
    "    \"\"\"\n",
    "    mu = profile_dict.get(\"mu\") or profile_dict.get(\"MU\")\n",
    "    if mu is None:\n",
    "        return float(fallback)\n",
    "    mu = np.asarray(mu, float)\n",
    "    if mu.ndim == 0:\n",
    "        return float(mu)\n",
    "    return float(np.mean(mu))\n",
    "\n",
    "def sample_params(n, *, Teff_min, Teff_max, g_min, g_max, fsed_min, fsed_max, kz_min, kz_max, seed=42):\n",
    "    rng = np.random.default_rng(seed)   # <-- create ONCE outside any loop\n",
    "    Teff = rng.uniform(Teff_min, Teff_max, size=n)\n",
    "    g    = rng.uniform(g_min,   g_max,   size=n)\n",
    "    fsed = rng.uniform(fsed_min, fsed_max, size=n)\n",
    "    kz   = 10 ** rng.uniform(np.log10(kz_min), np.log10(kz_max), size=n)  # log-uniform\n",
    "    return Teff, g, fsed, kz\n",
    "\n",
    "# To randomly sample gravity, fsed and kzz\n",
    "def rng_uniform(rng, lo, hi, size):\n",
    "    return rng.uniform(lo, hi, size=size)\n",
    "\n",
    "def rng_log_uniform(rng, lo, hi, size):\n",
    "    # Sample uniformly in log10 space\n",
    "    return 10.0 ** rng.uniform(np.log10(lo), np.log10(hi), size=size)\n",
    "\n",
    "def sanitize_float_for_name(x, fmt=\"{:.2e}\"):\n",
    "    # \"6.38e+09\" -> \"6.38e09\", \".\" ok on Windows, remove '+'\n",
    "    s = fmt.format(float(x)).replace(\"+\", \"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e23295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have a specific filename structure\n",
    "def make_case_filename(Teff, gravity, kzz, fsed, output_dir, ext=\".npz\"):\n",
    "    # Whether cloud or clear case\n",
    "    cloud_tag = \"clouds\"\n",
    "    base = f\"T{int(round(Teff))}G{int(round(gravity))}{cloud_tag}\"\n",
    "\n",
    "    base += f\"_Kzz{float(kzz):.2e}\"\n",
    "    base += f\"_fsed{float(fsed):.2f}\"\n",
    "\n",
    "    return os.path.join(output_dir, base + ext)\n",
    "\n",
    "# Save all files in one place\n",
    "def make_master_filename(n_spectra, waverange, R, output_dir, clouds=True, ext=\".npz\"):\n",
    "    cloud_tag = \"clouds\" if clouds else \"clear\"\n",
    "    # Encode basic config in the filename\n",
    "    wmin, wmax = waverange\n",
    "    base = f\"N{n_spectra}_R{int(R)}_{wmin:.2f}-{wmax:.2f}um_{cloud_tag}\"\n",
    "    return os.path.join(output_dir, base + ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08234b0",
   "metadata": {},
   "source": [
    "**SECTION 2:** Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4956426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_spectrum(waverange, gravity, Teff, kzz, fsed, mh, R,\n",
    "                opacity_db, sonora_db, virga_db):\n",
    "    \"\"\"\n",
    "    Compute a BD emission spectrum with optional Virga clouds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Opacity & inputs\n",
    "    opa = jdi.opannection(wave_range=list(waverange), filename_db=opacity_db)\n",
    "    bd = jdi.inputs(calculation=\"browndwarf\")\n",
    "\n",
    "    # Basic inputs\n",
    "    bd.phase_angle(0)\n",
    "    bd.gravity(gravity, gravity_unit=u.Unit('m/s**2'))\n",
    "    bd.sonora(sonora_db, Teff)\n",
    "\n",
    "\n",
    "    # Inject Kzz (must match pressure grid length)\n",
    "    prof = bd.inputs['atmosphere']['profile']\n",
    "    P = np.asarray(prof[\"pressure\"], float)\n",
    "    T = np.asarray(prof[\"temperature\"], float)\n",
    "    mmw = compute_mmw(prof)\n",
    "    \n",
    "    bd.inputs[\"atmosphere\"][\"profile\"][\"kz\"] = [float(kzz)] * len(P)\n",
    "    \n",
    "    # Clouds\n",
    "    cloud_list = autoselect_clouds(P, T, mmw)\n",
    "    bd.virga(cloud_list, virga_db, fsed=float(fsed), mh=mh, mmw=mmw)\n",
    "\n",
    "    out = bd.spectrum(opa, full_output=True)\n",
    "\n",
    "    # Convert to F_nu, then regrid to constant R in wavenumber\n",
    "    wn, th = out[\"wavenumber\"], out[\"thermal\"] # [cm^-1], [erg/cm^2/s/cm]\n",
    "    wl = 1e4/wn\n",
    "    flamy  = th * 1e-8                                # erg/cm^2/s/Å\n",
    "\n",
    "    sp = jdi.psyn.ArraySpectrum(wl, flamy,\n",
    "                                waveunits='um',\n",
    "                                fluxunits='FLAM')\n",
    "    \n",
    "    sp.convert('um')\n",
    "    sp.convert('Fnu')  # erg/cm^2/s/Hz\n",
    "    wn, th = sp.wave, sp.flux\n",
    "\n",
    "    # regrid in wavenumber to constant resolving power R\n",
    "    out['fluxnu'] = th\n",
    "\n",
    "    wn, th = jdi.mean_regrid(1e4/wn, th, R=R) #wavenumber, erg/cm2/s/Hz\n",
    "    out['regridy'] =  th\n",
    "    out['regridx'] = wn\n",
    "    \n",
    "    return wn, th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d78d6b",
   "metadata": {},
   "source": [
    "**SECTION 3:** Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c18f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sampling\n",
    "\n",
    "# Directories\n",
    "input_dir  = r\"C:\\Users\\Alex\\Desktop\\Picaso\\data\\sonora\" # Sonora db\n",
    "virga_dir  = r\"C:\\Users\\Alex\\Desktop\\Picaso\\data\\virga\" # Virga\n",
    "opacit_dir = None # Opacity db\n",
    "# Will change once runninng on Newton\n",
    "# r\"/groups/tkaralidi/opacity_500k_for_R5000_egpoutput.db\"\n",
    "output_dir = r\"C:\\Users\\Alex\\Desktop\\Picaso\\outputs\" # Output store\n",
    "\n",
    "# Ensure output dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "use_clouds = True # Clouds on/off\n",
    "\n",
    "# Wavelength and resolution\n",
    "wav_range       = (0.3, 3.0) # microns\n",
    "res_R           = 300 # Can change once opacity and TP change\n",
    "\n",
    "# Cloud microphysics\n",
    "MH              = 1.0   # [M/H] metallicity factor ~ solar\n",
    "\n",
    "# Sampling\n",
    "N_spectra       = 5 # Number of spectra to generate for sampling\n",
    "seed            = 2\n",
    "\n",
    "Teff_range      = (700, 1400)     # K\n",
    "gravity_range   = (50.0, 1500.0)  # m/s^2\n",
    "fsed_range      = (0.5, 5.0)      # dimensionless\n",
    "Kzz_range       = (1e8, 3e10)     # cm^2/s (log-uniform typical for BD)\n",
    "\n",
    "# Knobs\n",
    "save_per_case   = True   # Also save per-spectrum files with friendly names\n",
    "kzz_loguniform  = True   # Log-uniform sampling for Kzz (typical)\n",
    "VERBOSE         = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1f48d",
   "metadata": {},
   "source": [
    "**SECTION 4:** Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e500f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid(\n",
    "    n_spectra,\n",
    "    Teff_min, Teff_max,\n",
    "    g_min, g_max,\n",
    "    fsed_min, fsed_max,\n",
    "    kz_min, kz_max,\n",
    "    outdir,\n",
    "    R, wavmin, wavmax,\n",
    "    sonora_db, virga_db,\n",
    "    seed=123\n",
    "):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    Teff_arr, g_arr, fsed_arr, kz_arr = sample_params(\n",
    "        n_spectra,\n",
    "        Teff_min=Teff_min, Teff_max=Teff_max,\n",
    "        g_min=g_min, g_max=g_max,\n",
    "        fsed_min=fsed_min, fsed_max=fsed_max,\n",
    "        kz_min=kz_min, kz_max=kz_max,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Storage\n",
    "    X_rows = []\n",
    "    Y_rows = []\n",
    "    lam_ref = None\n",
    "\n",
    "    for i in range(n_spectra):\n",
    "        Teff_i = float(Teff_arr[i])\n",
    "        g_i    = float(g_arr[i])\n",
    "        fsed_i = float(fsed_arr[i])\n",
    "        kz_i   = float(kz_arr[i])\n",
    "\n",
    "        # ---- compute spectrum (clouds-only) ----\n",
    "        # Must return wavelength (µm) shape (nlam,), flux (nlam,)\n",
    "        lam_um, flux = bd_spectrum(\n",
    "            wavmin=wavmin, wavmax=wavmax,\n",
    "            gravity=g_i, Teff=Teff_i,\n",
    "            species=None,    # your cloud list is inside bd_spectrum for clouds-only\n",
    "            fsed=fsed_i, mh=1.0, mmw=2.2,\n",
    "            R=R, kz_value=kz_i,\n",
    "            sonora_db=sonora_db, virga_db=virga_db,\n",
    "            clouds=True\n",
    "        )\n",
    "\n",
    "        lam_um = np.asarray(lam_um, float).reshape(-1)     # <-- ensure (nlam,)\n",
    "        flux   = np.asarray(flux,   float).reshape(-1)\n",
    "\n",
    "        if lam_ref is None:\n",
    "            lam_ref = lam_um.copy()\n",
    "        else:\n",
    "            if lam_um.shape != lam_ref.shape or not np.allclose(lam_um, lam_ref, rtol=5e-7, atol=1e-8):\n",
    "                raise RuntimeError(\"Wavelength grid mismatch vs first case — check endpoints/R.\")\n",
    "\n",
    "        # Build X row [Teff[K], g[m/s^2], f_sed[-], Kz[cm^2/s]]\n",
    "        X_rows.append([Teff_i, g_i, fsed_i, kz_i])\n",
    "        Y_rows.append(flux)\n",
    "\n",
    "        # Unique, informative filename (no + in exponent)\n",
    "        f_T   = f\"T{int(round(Teff_i))}\"\n",
    "        f_G   = f\"G{int(round(g_i))}\"\n",
    "        f_Kzz = f\"Kzz{sanitize_float_for_name(kz_i, fmt='{:.2e}')}\"\n",
    "        f_fs  = f\"fsed{fsed_i:.2f}\"\n",
    "        fname = f\"{f_T}{f_G}clouds_{f_Kzz}_{f_fs}.npz\"\n",
    "        fpath = os.path.join(outdir, fname)\n",
    "\n",
    "        # If parameters collide (identical), avoid overwrite by suffixing an index\n",
    "        if os.path.exists(fpath):\n",
    "            base, ext = os.path.splitext(fpath)\n",
    "            fpath = f\"{base}_idx{i+1}{ext}\"\n",
    "\n",
    "        np.savez(\n",
    "            fpath,\n",
    "            x=np.array([[Teff_i, g_i, fsed_i, kz_i]], dtype=float),         # (1,4)\n",
    "            y=np.array([flux], dtype=float),                                # (1,nlam)\n",
    "            wavelength_um=lam_ref.astype(float)                             # (nlam,)\n",
    "        )\n",
    "        print(f\"[OK] Saved case {i+1} -> {fpath}\")\n",
    "\n",
    "    # Stack and one final dataset file (optional)\n",
    "    X = np.array(X_rows, dtype=float)                   # (n,4)\n",
    "    Y = np.vstack(Y_rows).astype(float)                 # (n,nlam)\n",
    "    bigpath = os.path.join(outdir, f\"dataset_T{int(Teff_min)}-{int(Teff_max)}_G{int(g_min)}-{int(g_max)}_R{int(R)}.npz\")\n",
    "    np.savez(bigpath, x=X, y=Y, wavelength_um=lam_ref.astype(float))\n",
    "    print(f\"[OK] Saved combined dataset -> {bigpath}\")\n",
    "\n",
    "    # Quick diagnostics\n",
    "    print(f\"Keys: ['x','y','wavelength_um']\")\n",
    "    print(f\"X shape: {X.shape} (columns: Teff[K], g[m/s^2], f_sed[-], Kz[cm^2/s])\")\n",
    "    print(f\"Y shape: {Y.shape} (flux_nu per spectrum)\")\n",
    "    print(f\"lam shape: {lam_ref.shape} (micron)\")\n",
    "    print(f\"Input ranges:\")\n",
    "    print(f\"  Teff [K]     : {X[:,0].min()} to {X[:,0].max()}\")\n",
    "    print(f\"  g [m/s^2]    : {X[:,1].min()} to {X[:,1].max()}\")\n",
    "    print(f\"  f_sed [-]    : {X[:,2].min()} to {X[:,2].max()}\")\n",
    "    print(f\"  Kz [cm^2/s]  : {X[:,3].min()} to {X[:,3].max()}\")\n",
    "    print(f\"Flux stats across all spectra: min={Y.min()} max={Y.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dfa057a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bd_spectrum() got an unexpected keyword argument 'wavmin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m sonora_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAlex\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPicaso\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msonora\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m virga_db  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAlex\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPicaso\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvirga\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mrun_grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_spectra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# how many random cases to generate\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTeff_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTeff_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mg_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# m/s^2\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfsed_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfsed_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkz_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkz_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# cm^2/s\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msonora_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msonora_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirga_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvirga_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mrun_grid\u001b[1;34m(n_spectra, Teff_min, Teff_max, g_min, g_max, fsed_min, fsed_max, kz_min, kz_max, outdir, R, wavmin, wavmax, sonora_db, virga_db, seed)\u001b[0m\n\u001b[0;32m     32\u001b[0m kz_i   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(kz_arr[i])\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# ---- compute spectrum (clouds-only) ----\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Must return wavelength (µm) shape (nlam,), flux (nlam,)\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m lam_um, flux \u001b[38;5;241m=\u001b[39m \u001b[43mbd_spectrum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwavmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwavmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwavmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgravity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTeff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTeff_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# your cloud list is inside bd_spectrum for clouds-only\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfsed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsed_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkz_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkz_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43msonora_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msonora_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirga_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvirga_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclouds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m lam_um \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(lam_um, \u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)     \u001b[38;5;66;03m# <-- ensure (nlam,)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m flux   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(flux,   \u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: bd_spectrum() got an unexpected keyword argument 'wavmin'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    outdir = r\"C:\\Users\\Alex\\Desktop\\Picaso\\outputs\"\n",
    "    sonora_db = r\"C:\\Users\\Alex\\Desktop\\Picaso\\data\\sonora\"\n",
    "    virga_db  = r\"C:\\Users\\Alex\\Desktop\\Picaso\\data\\virga\"\n",
    "\n",
    "    run_grid(\n",
    "        n_spectra=5,              # how many random cases to generate\n",
    "        Teff_min=700, Teff_max=1400,\n",
    "        g_min=300,  g_max=1000,   # m/s^2\n",
    "        fsed_min=1, fsed_max=4,\n",
    "        kz_min=1e7, kz_max=1e10,  # cm^2/s\n",
    "        outdir=outdir,\n",
    "        R=300, wavmin=3.0, wavmax=5.0,\n",
    "        sonora_db=sonora_db, virga_db=virga_db,\n",
    "        seed=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbd86d",
   "metadata": {},
   "source": [
    "**SECTION 5:** Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155e3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['x', 'y', 'wavelength_um']\n",
      "X shape: (1, 4)  (columns: Teff[K], g[m/s^2], f_sed[-], Kz[cm^2/s])\n",
      "Y shape: (1, 691)  (flux_nu per spectrum)\n",
      "lam shape: ()  (micron)\n",
      "\n",
      "Input ranges:\n",
      "  Teff [K]      : 700.0 to 700.0\n",
      "  g [m/s^2]     : 429.33758544921875 to 429.33758544921875\n",
      "  f_sed [-]     : 3.030195474624634 to 3.030195474624634\n",
      "  Kz [cm^2/s]   : 6378708480.0 to 6378708480.0\n",
      "\n",
      "Flux stats across all spectra:\n",
      "  min: 2.7680091654342758e-22  max: 1.6605585528850497e-07\n"
     ]
    }
   ],
   "source": [
    "# Path the the .NPZ folder\n",
    "\n",
    "npz_path = Path(r\"C:\\Users\\Alex\\Desktop\\Picaso\\outputs\\T700G429clouds_Kzz6.38e+09_fsed3.03.npz\")\n",
    "data = np.load(npz_path)\n",
    "\n",
    "# The file stores:\n",
    "# x -> inputs [Teff, g, f_sed, Kz] with shape (n_spectra, 4)\n",
    "# y -> spectra (flux_nu) with shape (n_spectra, n_lambda)\n",
    "# wavelength_um -> wavelength grid in microns (n_lambda,)\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "X = data[\"x\"]\n",
    "Y = data[\"y\"]\n",
    "lam = data[\"wavelength_um\"]\n",
    "\n",
    "n_spectra, n_inputs = X.shape\n",
    "print(f\"X shape: {X.shape}  (columns: Teff[K], g[m/s^2], f_sed[-], Kz[cm^2/s])\")\n",
    "print(f\"Y shape: {Y.shape}  (flux_nu per spectrum)\")\n",
    "print(f\"lam shape: {lam.shape}  (micron)\")\n",
    "\n",
    "print(\"\\nInput ranges:\")\n",
    "print(\"  Teff [K]      :\", float(X[:,0].min()), \"to\", float(X[:,0].max()))\n",
    "print(\"  g [m/s^2]     :\", float(X[:,1].min()), \"to\", float(X[:,1].max()))\n",
    "print(\"  f_sed [-]     :\", float(X[:,2].min()), \"to\", float(X[:,2].max()))\n",
    "print(\"  Kz [cm^2/s]   :\", float(X[:,3].min()), \"to\", float(X[:,3].max()))\n",
    "\n",
    "print(\"\\nFlux stats across all spectra:\")\n",
    "print(\"  min:\", float(Y.min()), \" max:\", float(Y.max()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picaso_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
